import streamlit as st
import pandas as pd
import os
import json
import shutil
import re
import time
import numpy as np


# å·¥å…·å‡½æ•°ï¼šè·¯å¾„å®‰å…¨æ–‡ä»¶å
def safe_file_name(name):
    return re.sub(r'[\/:*?"<>|]', "_", os.path.splitext(name)[0]).strip()

# åˆå§‹åŒ–çŠ¶æ€
def init_state():
    if 'df' not in st.session_state:
        st.session_state.df = None
    if 'selected_file' not in st.session_state:
        st.session_state.selected_file = None
    if 'processed_rows' not in st.session_state:
        st.session_state.processed_rows = set()
    if 'current_row' not in st.session_state:
        st.session_state.current_row = 0
    if 'deleted_rows' not in st.session_state:
        st.session_state.deleted_rows = []
    if 'working_dir' not in st.session_state:
        st.session_state.working_dir = None
    if 'dispute_count' not in st.session_state:
        st.session_state.dispute_count = {}

# rerun å…¼å®¹æ€§å¤„ç†
try:
    rerun = st.rerun
except AttributeError:
    rerun = st.experimental_rerun

# æ—¥å¿—è®°å½•
def append_log(action, row_index, deleted_row_data=None):
    log_path = os.path.join(st.session_state.working_dir, "log.jsonl")
    log_entry = {
        "action": action,
        "row_index": row_index,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
        "row_data": st.session_state.df.iloc[row_index].to_dict() if deleted_row_data is None else deleted_row_data
    }
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

    if action == "åˆ é™¤" and deleted_row_data is not None:
        deleted_path = os.path.join(st.session_state.working_dir, "deleted.csv")
        df_deleted = pd.DataFrame([deleted_row_data])
        if os.path.exists(deleted_path):
            df_deleted.to_csv(deleted_path, mode='a', index=False, header=False)
        else:
            df_deleted.to_csv(deleted_path, index=False)

# ä¿å­˜å®¡æ ¸è¿›åº¦
def save_progress(base_dir, is_inprogress=True):
    if st.session_state.df is not None:
        status = "inprogress" if is_inprogress else "audited"
        st.session_state.df.to_csv(os.path.join(base_dir, f"{status}.csv"), index=False)

        # â• æ–°å¢éƒ¨åˆ†ï¼šå®æ—¶ä¿å­˜ä¸€ä»½ audited.csvï¼ˆåªä¿å­˜å·²å®¡æ ¸è¡Œï¼‰
        audited_path = os.path.join(base_dir, "audited.csv")
        audited_df = st.session_state.df.iloc[list(st.session_state.processed_rows)]
        audited_df.to_csv(audited_path, index=False)

        # ä¿å­˜è¿›åº¦ä¿¡æ¯
        with open(os.path.join(base_dir, "progress.json"), "w", encoding="utf-8") as f:
            json.dump({
                "current_row": st.session_state.current_row,
                "processed_rows": list(st.session_state.processed_rows),
                "dispute_count": st.session_state.dispute_count
            }, f)

# åŠ è½½å®¡æ ¸è¿›åº¦
def load_progress(base_dir):
    inprogress_path = os.path.join(base_dir, "inprogress.csv")
    progress_path = os.path.join(base_dir, "progress.json")

    if os.path.exists(inprogress_path):
        st.session_state.df = pd.read_csv(inprogress_path)
    else:
        original_path = os.path.join(base_dir, "original.csv")
        st.session_state.df = pd.read_csv(original_path)

    if os.path.exists(progress_path):
        with open(progress_path, encoding="utf-8") as f:
            d = json.load(f)
            st.session_state.current_row = d.get("current_row", 0)
            st.session_state.processed_rows = set(d.get("processed_rows", []))
            st.session_state.dispute_count = d.get("dispute_count", {})

# æ¸²æŸ“è¾“å…¥æ¡†ï¼ˆæ–¹æ¡ˆ 2ï¼šç»Ÿä¸€ text_inputï¼Œå…¼å®¹ç©ºåˆ—ï¼‰
def render_input(col, val, row_idx):
    if pd.isna(val):
        val = ""
    return st.text_input(f"{col}", value=str(val), key=f"text_input_{col}_{row_idx}")

# å¼ºåˆ¶ç±»å‹è½¬æ¢
def try_cast(v, original):
    try:
        return type(original)(v)
    except:
        return v

# æŸ¥æ‰¾ä¸‹ä¸€ä¸ªæœªå¤„ç†çš„ç´¢å¼•
def next_unprocessed_index():
    total = len(st.session_state.df)
    for i in range(st.session_state.current_row + 1, total):
        if i not in st.session_state.processed_rows:
            return i
    for i in range(0, st.session_state.current_row):
        if i not in st.session_state.processed_rows:
            return i
    return total

# åˆå§‹åŒ–
init_state()
st.title("ğŸ“¦ æ³•æ¡æ¡ˆç”±å®¡æ ¸ç³»ç»Ÿ")
# é…ç½®è¾“å…¥æ–‡ä»¶å¤¹
INPUT_FOLDER = "input_data"  # ä½ æœ¬åœ°æ‰‹åŠ¨æ”¾ CSV æ–‡ä»¶çš„æ–‡ä»¶å¤¹

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(INPUT_FOLDER, exist_ok=True)

# æ‰«æ CSV æ–‡ä»¶
csv_files = []
for root, _, files in os.walk(INPUT_FOLDER):
    for file in files:
        if file.lower().endswith(".csv"):
            rel_path = os.path.relpath(os.path.join(root, file), INPUT_FOLDER)
            csv_files.append(rel_path)

# æ˜¾ç¤ºå¯é€‰ CSV
# if csv_files:
#     selected = st.selectbox("é€‰æ‹©è¦å®¡æ ¸çš„æ–‡ä»¶", csv_files)
# æ˜¾ç¤ºå¯é€‰ CSVï¼ˆå¸¦æœç´¢åŠŸèƒ½ï¼‰
if csv_files:
    search_term = st.text_input("ğŸ” è¾“å…¥å…³é”®è¯ç­›é€‰æ–‡ä»¶", "")
    filtered_files = [f for f in csv_files if search_term.lower() in f.lower()]

    if filtered_files:
        selected = st.selectbox("é€‰æ‹©è¦å®¡æ ¸çš„æ–‡ä»¶", filtered_files)
    else:
        st.warning("æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶")
        selected = None

    if selected:
        safe_name = safe_file_name(selected)
        working_dir = os.path.join("data", safe_name)
        os.makedirs(working_dir, exist_ok=True)

        if not os.path.exists(os.path.join(working_dir, "original.csv")):
            shutil.copy(os.path.join(INPUT_FOLDER, selected), os.path.join(working_dir, "original.csv"))

        st.session_state.selected_file = selected
        st.session_state.working_dir = working_dir
        st.session_state.current_row = 0
        st.session_state.processed_rows = set()
        st.session_state.deleted_rows = []
        st.session_state.dispute_count = {}

        load_progress(working_dir)
        st.success(f"å·²åŠ è½½æ–‡ä»¶ï¼š{selected}")
else:
    st.warning("âš ï¸ è¯·å°† CSV æ–‡ä»¶æ”¾å…¥ input_data æ–‡ä»¶å¤¹ä¸­")

# å®¡æ ¸é€»è¾‘
if st.session_state.df is not None:
    df = st.session_state.df
    idx = st.session_state.current_row

    if idx < len(df):
        row = df.iloc[idx]
        st.write(f"å½“å‰å®¡æ ¸ç¬¬ {idx + 1} / {len(df)} è¡Œ")
        st.dataframe(row.to_frame())

        # é€‰æ‹©æ“ä½œ
        op = st.radio("é€‰æ‹©æ“ä½œ", ["é€šè¿‡", "ä¿®æ”¹", "åˆ é™¤"], key=f"op_radio_{idx}")

        # ä¿®æ”¹
        if op == "ä¿®æ”¹":
            new_vals = {col: render_input(col, row[col], idx) for col in df.columns}
            if st.button("ä¿å­˜ä¿®æ”¹", key=f"save_mod_{idx}"):
                for c, v in new_vals.items():
                    df.at[idx, c] = try_cast(v, row[c])
                append_log("ä¿®æ”¹", idx)
                st.session_state.processed_rows.add(idx)
                st.session_state.current_row = next_unprocessed_index()
                save_progress(st.session_state.working_dir, True)
                rerun()

        # åˆ é™¤
        elif op == "åˆ é™¤":
            if st.button("ç¡®è®¤åˆ é™¤", key=f"confirm_delete_{idx}"):
                deleted_data = df.iloc[idx].to_dict()
                append_log("åˆ é™¤", idx, deleted_row_data=deleted_data)

                df.drop(idx, inplace=True)
                df.reset_index(drop=True, inplace=True)

                # é‡æ–°æ˜ å°„ processed_rows
                st.session_state.processed_rows = {
                    new_idx
                    for new_idx in range(len(df))
                    if new_idx != idx  # è¢«åˆ æ‰
                       and new_idx in st.session_state.processed_rows
                }

                # é‡æ–°å®šä½ä¸‹ä¸€ä¸ªæœªå¤„ç†çš„ index
                unprocessed = set(range(len(df))) - st.session_state.processed_rows
                st.session_state.current_row = min(unprocessed) if unprocessed else len(df)

                save_progress(st.session_state.working_dir, True)
                rerun()


        # é€šè¿‡
        else:
            if st.button("é€šè¿‡", key=f"pass_{idx}"):
                append_log("é€šè¿‡", idx)
                st.session_state.processed_rows.add(idx)
                st.session_state.current_row = next_unprocessed_index()
                save_progress(st.session_state.working_dir, True)
                rerun()

        st.markdown("---")
        # ===== æ–°å¢çº çº·ç±»å‹ =====
        st.markdown("### â• æ–°å¢çº çº·ç±»å‹")
        new_dispute_type = st.text_input("è¾“å…¥æ–°çº çº·ç±»å‹", key=f"new_dispute_type_{idx}")

        if st.button("æ–°å¢çº çº·ç±»å‹", key=f"add_dispute_type_{idx}"):
            # 1ï¸âƒ£ æŸ¥æ‰¾å·²æœ‰ dispute_type_ åˆ—
            existing_cols = [col for col in df.columns if col.startswith("dispute_type_")]
            next_index = len(existing_cols) + 1
            new_col = f"dispute_type_{next_index}"

            # 2ï¸âƒ£ å¦‚æœæ–°åˆ—ä¸å­˜åœ¨ï¼Œå¢åŠ ç©ºåˆ—
            if new_col not in df.columns:
                df[new_col] = ""

            # 3ï¸âƒ£ å½“å‰è¡Œæ›´æ–°æ•°æ®
            df.at[idx, new_col] = new_dispute_type.strip()

            # 4ï¸âƒ£ æ—¥å¿—ä¿å­˜
            append_log("æ–°å¢çº çº·ç±»å‹", idx)
            save_progress(st.session_state.working_dir, True)

            # 5ï¸âƒ£ é¡µé¢åˆ·æ–°
            rerun()

        st.markdown("---")

    else:
        st.success("âœ… å®¡æ ¸å®Œæˆ")
        if st.button("å¯¼å‡ºå®¡æ ¸ç»“æœ"):
            save_progress(st.session_state.working_dir, False)

    # å®¡æ ¸è¿›åº¦æ¡
    st.progress(len(st.session_state.processed_rows) / max(1, len(df)))
    st.write(f"å·²å®¡æ ¸ {len(st.session_state.processed_rows)} / {len(df)} è¡Œ")

    # # å®¡æ ¸è®°å½•æ”¯æŒå…³é”®è¯æœç´¢ + åˆ†é¡µå±•ç¤º
    # log_path = os.path.join(st.session_state.working_dir, "log.jsonl")
    # if os.path.exists(log_path):
    #     with open(log_path, "r", encoding="utf-8") as f:
    #         logs = [json.loads(line) for line in f.readlines()]
    #
    #     if logs:
    #         # æœç´¢æ¡†
    #         keyword = st.text_input("ğŸ” è¾“å…¥å…³é”®è¯æœç´¢ï¼ˆæ”¯æŒè¡Œå·ã€æ“ä½œã€å­—æ®µå†…å®¹ï¼‰", key="log_search_input").strip()
    #
    #         # è¿‡æ»¤æ—¥å¿—
    #         if keyword:
    #             keyword_lower = keyword.lower()
    #
    #
    #             def match(log_entry):
    #                 if keyword_lower in str(log_entry["row_index"]).lower():
    #                     return True
    #                 if keyword_lower in str(log_entry["action"]).lower():
    #                     return True
    #                 if keyword_lower in str(log_entry.get("timestamp", "")).lower():
    #                     return True
    #                 row_data = log_entry.get("row_data", {})
    #                 for v in row_data.values():
    #                     if keyword_lower in str(v).lower():
    #                         return True
    #                 return False
    #
    #
    #             filtered_logs = [log for log in logs if match(log)]
    #         else:
    #             filtered_logs = logs
    #
    #         # åˆ†é¡µ
    #         logs_per_page = 10
    #         total_pages = (len(filtered_logs) + logs_per_page - 1) // logs_per_page
    #
    #         if "log_page" not in st.session_state:
    #             st.session_state.log_page = 0
    #         # å¦‚æœæœç´¢äº†ï¼Œè‡ªåŠ¨è·³å›ç¬¬ä¸€é¡µ
    #         if keyword and st.session_state.log_page != 0:
    #             st.session_state.log_page = 0
    #
    #         st.markdown(
    #             f"### ğŸ“ å®¡æ ¸è®°å½•ï¼ˆå…± {len(filtered_logs)} æ¡ï¼Œå½“å‰ç¬¬ {st.session_state.log_page + 1} é¡µ / å…± {total_pages} é¡µï¼‰")
    #
    #         start_idx = st.session_state.log_page * logs_per_page
    #         end_idx = min(start_idx + logs_per_page, len(filtered_logs))
    #
    #         for i in range(start_idx, end_idx):
    #             log_entry = filtered_logs[i]
    #             row_idx = log_entry["row_index"]
    #             action = log_entry["action"]
    #             timestamp = log_entry["timestamp"]
    #             st.write(f"**è¡Œå·ï¼š {row_idx}ï¼Œæ“ä½œï¼š{action}ï¼Œæ—¶é—´ï¼š{timestamp}**")
    #
    #             row_data = log_entry.get("row_data")
    #             if row_data:
    #                 df_row = pd.DataFrame([row_data])
    #                 st.dataframe(df_row)
    #
    #             btn_key = f"re_audit_{i}_{row_idx}"
    #             if st.button("é‡æ–°å®¡æ ¸", key=btn_key):
    #                 if row_idx in st.session_state.processed_rows:
    #                     st.session_state.processed_rows.remove(row_idx)
    #
    #                 if action == "åˆ é™¤":
    #                     deleted_data = log_entry.get("row_data")
    #                     if deleted_data is not None:
    #                         df = st.session_state.df
    #                         insert_pos = min(row_idx, len(df))
    #                         restored_df = pd.DataFrame([deleted_data])
    #                         df_top = df.iloc[:insert_pos]
    #                         df_bottom = df.iloc[insert_pos:]
    #                         df = pd.concat([df_top, restored_df, df_bottom], ignore_index=True)
    #                         st.session_state.df = df
    #
    #                 st.session_state.current_row = row_idx
    #                 save_progress(st.session_state.working_dir, True)
    #                 st.rerun()
    #
    #         # åˆ†é¡µæŒ‰é’®æ”¾ä¸‹é¢
    #         st.markdown("---")
    #         col1, col2, col3 = st.columns([1, 6, 1])
    #         with col1:
    #             if st.button("â¬… ä¸Šä¸€é¡µ") and st.session_state.log_page > 0:
    #                 st.session_state.log_page -= 1
    #         with col3:
    #             if st.button("ä¸‹ä¸€é¡µ â¡") and st.session_state.log_page < total_pages - 1:
    #                 st.session_state.log_page += 1
    # å®¡æ ¸è®°å½•æ”¯æŒå…³é”®è¯æœç´¢ + åˆ†é¡µå±•ç¤º
    log_path = os.path.join(st.session_state.working_dir, "log.jsonl")
    if os.path.exists(log_path):
        with open(log_path, "r", encoding="utf-8") as f:
            logs = [json.loads(line) for line in f.readlines()]
        logs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)

        if logs:
            keyword = st.text_input("ğŸ” è¾“å…¥å…³é”®è¯æœç´¢ï¼ˆæ”¯æŒè¡Œå·ã€æ“ä½œã€å­—æ®µå†…å®¹ï¼‰", key="log_search_input").strip()

            if keyword:
                keyword_lower = keyword.lower()


                def match(log_entry):
                    if keyword_lower in str(log_entry["row_index"]).lower():
                        return True
                    if keyword_lower in str(log_entry["action"]).lower():
                        return True
                    if keyword_lower in str(log_entry.get("timestamp", "")).lower():
                        return True
                    row_data = log_entry.get("row_data", {})
                    for v in row_data.values():
                        if keyword_lower in str(v).lower():
                            return True
                    return False


                filtered_logs = [log for log in logs if match(log)]
            else:
                filtered_logs = logs

            logs_per_page = 10
            total_pages = (len(filtered_logs) + logs_per_page - 1) // logs_per_page

            if "log_page" not in st.session_state:
                st.session_state.log_page = 0
            if keyword and st.session_state.log_page != 0:
                st.session_state.log_page = 0

            st.markdown(
                f"### ğŸ“ å®¡æ ¸è®°å½•ï¼ˆå…± {len(filtered_logs)} æ¡ï¼Œå½“å‰ç¬¬ {st.session_state.log_page + 1} é¡µ / å…± {total_pages} é¡µï¼‰")

            start_idx = st.session_state.log_page * logs_per_page
            end_idx = min(start_idx + logs_per_page, len(filtered_logs))

            for i in range(start_idx, end_idx):
                log_entry = filtered_logs[i]
                row_idx = log_entry["row_index"]
                action = log_entry["action"]
                timestamp = log_entry["timestamp"]

                header_text = f"ã€{i + 1}ã€‘è¡Œå·: {row_idx}ï¼Œæ“ä½œ: {action}ï¼Œæ—¶é—´: {timestamp}"
                with st.expander(header_text, expanded=False):
                    row_data = log_entry.get("row_data", {})
                    clean_data = {k: ("" if (isinstance(v, float) and np.isnan(v)) else v) for k, v in row_data.items()}
                    st.json(clean_data)

                    btn_key = f"re_audit_{i}_{row_idx}"
                    if st.button("é‡æ–°å®¡æ ¸", key=btn_key):
                        if row_idx in st.session_state.processed_rows:
                            st.session_state.processed_rows.remove(row_idx)

                        if action == "åˆ é™¤":
                            deleted_data = log_entry.get("row_data")
                            if deleted_data is not None:
                                df = st.session_state.df
                                insert_pos = min(row_idx, len(df))
                                restored_df = pd.DataFrame([deleted_data])
                                df_top = df.iloc[:insert_pos]
                                df_bottom = df.iloc[insert_pos:]
                                df = pd.concat([df_top, restored_df, df_bottom], ignore_index=True)
                                st.session_state.df = df

                        st.session_state.current_row = row_idx
                        save_progress(st.session_state.working_dir, True)
                        st.rerun()

            # åˆ†é¡µæŒ‰é’®
            # st.markdown("---")
            # col1, col2, col3 = st.columns([1, 6, 1])
            # with col1:
            #     if st.button("ä¸Šä¸€é¡µ") and st.session_state.log_page > 0:
            #         st.session_state.log_page -= 1
            # with col3:
            #     if st.button("ä¸‹ä¸€é¡µ") and st.session_state.log_page < total_pages - 1:
            #         st.session_state.log_page += 1
            st.markdown("---")
            col1, col2, col3 = st.columns([1, 6, 1])

            with col1:
                if st.button("è·³è½¬åˆ°ç¬¬ä¸€é¡µ"):
                    st.session_state.log_page = 0
                if st.button("ä¸Šä¸€é¡µ") and st.session_state.log_page > 0:
                    st.session_state.log_page -= 1

            with col3:
                if st.button("ä¸‹ä¸€é¡µ") and st.session_state.log_page < total_pages - 1:
                    st.session_state.log_page += 1
                if st.button("è·³è½¬åˆ°æœ€åä¸€é¡µ"):
                    st.session_state.log_page = total_pages - 1

    # ä¸‹è½½åŒº
    if st.session_state.df is not None:
        audited_df = st.session_state.df.iloc[list(st.session_state.processed_rows)]
        audited_csv = audited_df.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ“¥ ä¸‹è½½å·²å®¡æ ¸æ•°æ®", audited_csv, file_name="audited_data.csv", mime='text/csv')

    if os.path.exists(log_path):
        with open(log_path, "r", encoding="utf-8") as f:
            logs_bytes = f.read().encode("utf-8")
        st.download_button("ğŸ“œ ä¸‹è½½å®¡æ ¸æ—¥å¿—ï¼ˆlog.jsonlï¼‰", logs_bytes, file_name="log.jsonl", mime="application/json")

